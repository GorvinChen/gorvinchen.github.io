<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="ML,SVM," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="简介支持向量机（support vector machine，SVM）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。">
<meta name="keywords" content="ML,SVM">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM">
<meta property="og:url" content="http://yoursite.com/2018/01/04/SVM/index.html">
<meta property="og:site_name" content="ScNico">
<meta property="og:description" content="简介支持向量机（support vector machine，SVM）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。">
<meta property="og:updated_time" content="2018-01-06T00:03:59.306Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SVM">
<meta name="twitter:description" content="简介支持向量机（support vector machine，SVM）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/01/04/SVM/"/>





  <title> SVM | ScNico </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?73df29d2013644d2ca9cd21eefcb68c2";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ScNico</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/04/SVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ScNico">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ScNico">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                SVM
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-04T16:38:21+08:00">
                2018-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>支持向量机（support vector machine，SVM）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。<a id="more"></a>对于二分类问题，SVM将实例表示为空间中的点，通过映射实例被超平面以尽可能宽的间隔分开。并通过将新的实例映射到同一空间，基于它们落在间隔的哪一侧来预测其所属的类别。除了进行线性分类之外，SVM还可以使用核方法有效地进行非线性分类，将其输入隐式映射到高维特征空间中。</p>
<h3 id="线性可分"><a href="#线性可分" class="headerlink" title="线性可分"></a>线性可分</h3><p>给定线性可分的训练数据集，通过间隔最大化得到分离的超平面为 $w^T x+b=0$，称之为 $(w, b)$，相应的分类决策函数为</p>
<script type="math/tex; mode=display">
f(x) = sign(w^Tx+b)</script><p>称之为线性可分支持向量机。对于样本空间中任意点 $x$ 到超平面的距离可以写为</p>
<script type="math/tex; mode=display">
\gamma = \frac{|w^Tx+b|}{\left \| w \right \|}</script><p>在很多的资料中都会假定在二分类问题中 $y$ 的取值为 $\pm 1 $，然后将 $yf(x)$ 式称为函数间隔，而将 $\frac{yf(x)}{\left | w \right |}$ 称为几何间隔，这是因为正确分类时 $yf(x) \geqslant 0$。其实与这里的取绝对值类似，而 $y$ 的取值当然还可以取其他的值，为了方便推导所以取了 $\pm 1$。</p>
<p>而在</p>
<h4 id="最大间隔"><a href="#最大间隔" class="headerlink" title="最大间隔"></a>最大间隔</h4><p>对于某条样本来说，该样本离超平面的间隔越大则分类的置信度越高，为了使分类的置信度尽量高，我们可以最大化间隔 $\frac{1}{\left | w \right |}$，而这相当于最小化 $\frac{1}{2} \left | w \right |^2$，所以该问题被转化成如下的形式</p>
<script type="math/tex; mode=display">
\begin{align*}
&\min_{w,b} \frac{1}{2} \left \| w \right \|^2 \\
&s.t.\ y_i(x^Tx_i + b) \geqslant 1, \ i=1,2,\cdots,n
\end{align*}</script><p>而根据<a href="">拉格朗日对偶性</a>我们可以定义</p>
<script type="math/tex; mode=display">
L(w,b,\alpha)=\frac{1}{2} \left \| w \right \|^2  + \sum_i^n{\alpha_i [1-y_i(w^Tx_i+b)]},\ \alpha_i \geqslant0</script><p>并将原始问题转化为对偶问题求解</p>
<script type="math/tex; mode=display">
\min_{w, b}  \max_{\alpha} L(x, b, \alpha) \Rightarrow \max_{\alpha} \min_{w, b}   L(x, b, \alpha)</script><p>转化为对偶问题的优点有两个：一是对偶问题往往更容易求解；二是自然引入核函数，进而推广到非线性分类。</p>
<h4 id="求解对偶问题"><a href="#求解对偶问题" class="headerlink" title="求解对偶问题"></a>求解对偶问题</h4><h5 id="求解极小问题"><a href="#求解极小问题" class="headerlink" title="求解极小问题"></a>求解极小问题</h5><p>首先固定 $\alpha$，求解 $\min_{w, b}   L(w, b)$，分别对 $w$ 和 $b $ 求导得到</p>
<script type="math/tex; mode=display">
\frac{\partial  L}{\partial  w}=0 \Rightarrow w=\sum_{i=1}^n \alpha_i y_i x_i</script><script type="math/tex; mode=display">
\frac{\partial  L}{\partial  b}=0 \Rightarrow \sum_{i=1}^n \alpha_i y_i=0</script><p>将结果带入 $L(w,b,\alpha)$ 消去 $w$ 和 $b $ 后得到只含有变量 $\alpha$ 的式子</p>
<script type="math/tex; mode=display">
\begin{align*}
L(w,b,\alpha)&=\frac{1}{2} \left \| w \right \|^2  + \sum_i^n{\alpha_i [1-y_i(w^Tx_i+b)]} \\
&=\frac{1}{2}w^T\sum_{i=1}^n \alpha_i y_i x_i-w^T\sum_{i=1}^n \alpha_i y_i x_i - b\sum_{i=1}^n \alpha_i y_i + \sum_{i=1}^n \alpha_i \\
&= \sum_{i=1}^n \alpha_i - \frac{1}{2}(\sum_{i=1}^n \alpha_i y_i x_i )^T\sum_{i=1}^n \alpha_i y_i x_i \\
&=\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j \\

\end{align*}</script><h5 id="求解极大问题"><a href="#求解极大问题" class="headerlink" title="求解极大问题"></a>求解极大问题</h5><p>消去 $w$ 和 $b$ 后得到只含有变量 $\alpha$ 的 $L(\alpha)$，然后我们求解极大问题</p>
<script type="math/tex; mode=display">
\begin{align*}
&\max_\alpha \  \sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j \\
&s.t.\ \begin{cases}
\sum_{i=1}^n \alpha_i y_i = 0\\
\alpha_i \geqslant 0,                 &i=1,2,\cdots,n
\end{cases}
\end{align*}</script><h5 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h5><p>SMO(Sequential Minimal Optimization)算法是一种启发式算法，主要用来求解<a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92" target="_blank" rel="external">二次规划问题</a>。其基本思想是若所有变量的解都满足该最优化问题的KTT条件，由于KTT条件是求解该最优化问题的充分必要条件，所以最优化问题的解就得到了。</p>
<p>上述极大问题等价于求解极小问题</p>
<script type="math/tex; mode=display">
\begin{align*}
&\min_\alpha \  \frac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(x_i, x_j) - \sum_{i=1}^n \alpha_i\\
\\
&s.t.\ \begin{cases}
\sum_{i=1}^n \alpha_i y_i = 0\\
\\
\alpha_i \geqslant 0,                 &i=1,2,\cdots,n
\end{cases}
\end{align*}</script><p>而该极小化问题正好是一个二次规划问题，我们可以通过SMO算法来求解。一般的优化算法通过梯度方法每次优化一个变量（固定其他变量）求解二次规划问题的最值，而上述问题由于限制条件 $\sum<em>{i=1}^n \alpha_i y_i = 0$ 存在，若每次改变更新一个 $\alpha_i$ ，则更新后显然不满足约束条件 $\sum</em>{i=1}^n \alpha_i y_i = 0$。所以SMO算法通过每次选择两个变量 $\alpha_i$ 和 $\alpha_j$ 进行优化（固定其他变量）。这样针对两个变量构建二次规划问题，这个子问题的解更接近于原始二次规划问题的解。</p>
<ul>
<li><p>算法步骤</p>
<p>while  未收敛 do</p>
<ul>
<li>通过启发式方法选取 $\alpha_i$ 和 $\alpha_j$ </li>
<li>固定 $\alpha_i$ 和 $\alpha_j$ 以外的参数，求解上述极小问题并更新 $\alpha_i$ 和 $\alpha_j$ </li>
</ul>
</li>
</ul>
<h6 id="选择变量"><a href="#选择变量" class="headerlink" title="选择变量"></a>选择变量</h6><p>那么什么是启发式方法来选取 $\alpha_i$ 和 $\alpha_j$ 呢，这要从原始问题转化为对偶问题说起，我们在将原始问题转化为对偶问题后，因为不等式约束的缘故，需要满足<a href="">KKT条件</a>，即要求</p>
<script type="math/tex; mode=display">
\begin{cases}
\alpha_i(y_i f(x_i) - 1)=0\\
\\
\alpha_i \geqslant 0\\
\\
y_i f(x_i) - 1 \geqslant 0\\
\end{cases}</script><p>所以对于任意训练样本 $(x_i, y_i)$，总有 $\alpha_i=0$ 或者 $y_i f(x_i) = 1$。</p>
<ul>
<li>$\alpha_i = 0$，即乘子为 0，约束 $g_i(x)$ 不起作用</li>
<li>$\alpha_i &gt; 0$，即 <script type="math/tex">y_i f(x_i) = 1</script>，所对应的样本点位于最大间隔的边界上，称之为<strong>支持向量</strong></li>
</ul>
<p>注意到只需要选取的 $\alpha_i$ 和 $\alpha_j$ 中有一个不满足KTT条件，目标函数在迭代后就会增大</p>
<h6 id="二次规划求解"><a href="#二次规划求解" class="headerlink" title="二次规划求解"></a>二次规划求解</h6><p>不失一般性，假设选取 $\alpha_1$ 和 $\alpha_2$，剩余变量固定，则问题可以写成</p>
<script type="math/tex; mode=display">
\begin{align*}
\min_{\alpha_1,\alpha_2}\ W(\alpha_1,\alpha_2)=&\frac{1}{2}K_{11}\alpha_1^2+\frac{1}{2}K_{22}\alpha_2^2+y_1y_2K_{12}\alpha_1\alpha_2\\
&-(\alpha_1+\alpha_2)+y_1\alpha_1\sum_{i=3}^ny_i\alpha_iK_{i1}+y_2\alpha_2\sum_{i=3}^ny_i\alpha_iK_{i2}\\
\\
\end{align*}</script><script type="math/tex; mode=display">
s.t.\ \begin{cases}
\alpha_1y_1+\alpha_2y_2=-\sum_{i=3}^ny_i\alpha_i=\xi \\
\\
0 \leqslant \alpha_i \leqslant C,&i=1,2
\end{cases}</script><h3 id="线性不可分"><a href="#线性不可分" class="headerlink" title="线性不可分"></a>线性不可分</h3><p>我们之假定了训练样本是线性可分的，即存在某超平面可以将训练样本正确分类，而在实际的问题中，原始样本空间或许并不能由某个超平面正确分类。对于这样的问题可以通过将原始的样本空间映射到更高维的特征空间，使得样本在特征空间中线性可分。</p>
<h4 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h4><p>原始的用非线性可分的数据去训练一个线性分类器，通常的做法就是将原始样本空间映射到特征空间，然后在特征空间中训练线性分类器。而核函数的方法则是直接将特征空间的映射以及内积融合在一起，并且解决了映射函数维度爆炸的问题（多项式核中将会举一个简单的例子）。</p>
<p>首先定义 $\phi(x_i)$ 表示样本 $x_i$ 映射到特征空间的特征向量，定义核函数如下所示</p>
<script type="math/tex; mode=display">
\kappa(x_i,x_j)=\left \langle \phi(x_i),\phi(x_j)  \right \rangle= \phi(x_i)^T\phi(x_j)</script><p>考虑我们得到的线性可分函数</p>
<script type="math/tex; mode=display">
f(x)=(\sum_{i=1}^n\alpha_iy_ix_i)^Tx+b\Rightarrow f(\phi(x))=\sum_{i=1}^n\alpha_iy_i\kappa(x_i,x)+b</script><p>下面将介绍几个常见的核函数。</p>
<h5 id="多项式核"><a href="#多项式核" class="headerlink" title="多项式核"></a>多项式核</h5><script type="math/tex; mode=display">
\kappa(x_i,x_j)=(x_i^Tx_j+c)^d</script><p>考虑简单的二维样本空间，$x_i=(a_1, a_2)^T$，$x_j=(b_1,b_2)^T$，并取 $d=2$，分别取 $c=0$ 和 $c=1$</p>
<script type="math/tex; mode=display">
\begin{align*}
\\
&\left \langle x_i, x_j \right \rangle=a_1b_1+a_2b_2 \\
\\
&(\left \langle x_i, x_j \right \rangle) ^2=a_1^2b_1^2+2a_1b_1a_2b_2+  a_2^2b_2 ^2\\
\\
&(\left \langle x_i, x_j \right \rangle + 1) ^2=a_1^2b_1^2+2a_1b_1a_2b_2+  a_2^2b_2 ^2+2a_1b_1+2a_2b_2 +1
\end{align*}</script><p>可以取映射 $\phi_1(x_i)=(a_1^2,\sqrt2a_1a_2,a_2^2)^T$ 则可以将原样本空间映射到三维空间，与上式中第二个式子类似；取映射 $\phi_2(x_i)=(a_1^2,\sqrt2a_1a_2,a_2^2,\sqrt2 a_1,\sqrt2 a_2, 1)^T$ 则可以将原样本空间映射到五维空间，得到的结果与上式中第三个式子类似。考虑如果继续增大 $d$，那么如果我们通过原始的方法先映射到特征空间则需要映射到更多的维度，而如果用核函数则不存在这个维度爆炸的问题。</p>
<h5 id="高斯核"><a href="#高斯核" class="headerlink" title="高斯核"></a>高斯核</h5><p>高斯核又称高斯径向基函数(radial basis function)，该核函数可以将原始的样本空间映射到无穷维，其形式如下所示</p>
<script type="math/tex; mode=display">
\begin{align*}
\\
\kappa(x_i,x_j)&=\exp(-\frac{\left \|x_i-x_j  \right \|^2}{2\sigma^2}) \\
&= \exp(-\frac{\left \|x_i \right \|^2 + \left \|x_j  \right \|^2 - 2x_i^Tx_j}{2\sigma^2})\\
&= \exp(-\frac{\left \|x_i \right \|^2 }{2\sigma^2})\exp(-\frac{\left \|x_j \right \|^2 }{2\sigma^2})\exp(\frac{ 2x_i^Tx_j}{2\sigma^2})
\end{align*}</script><p>根据指数函数的泰勒公式</p>
<script type="math/tex; mode=display">
\exp(x)=\sum_{n=0}^\infty \frac{x^n}{n!}</script><p>所以继续变换</p>
<script type="math/tex; mode=display">
\kappa(x_i,x_j)== \exp(-\frac{\left \|x_i \right \|^2 }{2\sigma^2})\exp(-\frac{\left \|x_j \right \|^2 }{2\sigma^2}) \sum_{n=0}^\infty \frac{ (2x_i^Tx_j)^n}{2\sigma^2n!}</script><p>根据泰勒展开式我们可以看到高斯核可以将数据映射到无穷维空间。</p>
<h5 id="其他核函数"><a href="#其他核函数" class="headerlink" title="其他核函数"></a>其他核函数</h5><p>当然除了多项式核以及高斯核以外还有很多核函数，下面将列出常见的核函数</p>
<ul>
<li><p>线性核</p>
<p>线性核实际上就是原始空间的内积，这个核主要是为了方便工程实现，不用将线性和非线性SVM分开，全部都用非线性来表示，只不过带入的核函数不同。</p>
<script type="math/tex; mode=display">
\kappa(x_i,x_j)=x_i^Tx_j</script></li>
</ul>
<ul>
<li><p>拉普拉斯核</p>
<p>$ \sigma &gt; 0 $ </p>
<script type="math/tex; mode=display">
\kappa(x_i,x_j)=\exp(-\frac{\left \|x_i-x_j  \right \|}{\sigma})</script></li>
<li><p>sigmoid核</p>
<p>$\beta&gt;0$，$\theta&lt;0$</p>
<script type="math/tex; mode=display">
\kappa(x_i,x_j)=\tanh(\beta x_i^Tx_j+\theta)</script></li>
</ul>
<h4 id="软间隔"><a href="#软间隔" class="headerlink" title="软间隔"></a>软间隔</h4><p>在之前的讨论中，我们都假定了训练数据的样本空间或者特征空间是线性可分的，然而在实际任务中往往很难确定是否线性可分。缓解该问题的办法是允许支持向量机在一些样本上出错，所以便引入了软间隔，或者说松弛变量，即允许某些样本不满足约束 $y_if(x_i)\geq1$</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><h3 id="支持向量机回归"><a href="#支持向量机回归" class="headerlink" title="支持向量机回归"></a>支持向量机回归</h3><h3 id="拉格朗日对偶性"><a href="#拉格朗日对偶性" class="headerlink" title="拉格朗日对偶性"></a>拉格朗日对偶性</h3><h5 id="原始问题"><a href="#原始问题" class="headerlink" title="原始问题"></a>原始问题</h5><p>假设 $f(x)$，$g_i(x)$，$h_j(x)$ 是定义在 $\mathbf{R}^n$上的连续可微函数，考虑约束的最优化问题</p>
<script type="math/tex; mode=display">
\begin{align*}

&\min_{x \in \mathbf{R}^n} f(x) \\
\\
&s.t.\quad
\begin{cases}
g_i(x) \leqslant 0，& i=1,2,\cdots,k\\
\\
h_j(x) = 0,                 &j=1,2,\cdots,l
\end{cases}
\end{align*}</script><p>引进拉格朗日函数</p>
<script type="math/tex; mode=display">
L(x, \alpha, \beta) = f(x) + \sum_{i=1}^{k} \alpha_i g_i(x) + \sum_{j=1}^{l} \beta_j h_j(x),\ \alpha_i \geqslant 0</script><p>将关于 $x$ 的函数 $\Theta_P(x)$ 称为原始问题：</p>
<script type="math/tex; mode=display">
\Theta_P(x) = \max_{\alpha, \beta: \alpha_i \geqslant 0} L(x, \alpha, \beta)</script><p>假设给定某个 $x$，若 $x$ 违反原始问题的约束条件，即存在某个约束 $i$ 使得 $g_i(x) &gt; 0$ 或者某个 $j$ 使得 $h_j(x)=0$，我们可以分别让 $\alpha_i \rightarrow +\infty$，$\beta_j h_j(x) \rightarrow +\infty$ 而其余的 $\alpha$ 和 $\beta$ 都取为 0，则 $\Theta_P(x)=+\infty$；相反如 $x$ 满足约束条件，则 $\Theta_P(x)=f(x)$。所以对于</p>
<script type="math/tex; mode=display">
\min_{x} \Theta_P(x) = \min_{x}  \max_{\alpha, \beta: \alpha_i \geqslant 0} L(x, \alpha, \beta)</script><p>来说其与原始我们想要求解的问题是等价的，原始问题便被我们转化成了极小极大问题。我们定义 $\min_{x} \Theta_P(x)$ 为原始问题，而  $p^*$ 为原始问题的最优解。</p>
<h5 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h5><p>有时候解原始问题是非常困难的，所以通常可以通过求解对偶问题而得到原始问题的解。对偶问题的定义如下所示：</p>
<script type="math/tex; mode=display">
\max_{\alpha, \beta: \alpha_i \geqslant 0} \Theta_D(x) = \max_{\alpha, \beta: \alpha_i \geqslant 0} \min_{x}   L(x, \alpha, \beta)</script><p>这样问题就由原来的极小极大问题转化成了极大极小问题。我们定义 $\max_{\alpha, \beta: \alpha_i \geqslant 0} \Theta_D(x)$ 为原始问题的对偶问题，$d^*$为对偶问题的最优解。</p>
<h5 id="原始问题与对偶问题"><a href="#原始问题与对偶问题" class="headerlink" title="原始问题与对偶问题"></a>原始问题与对偶问题</h5><p>若原始问题和对偶问题都有最优解，则</p>
<script type="math/tex; mode=display">
\Theta_D(\alpha,\beta)=\min_xL(x, \alpha, \beta) \leqslant L(x, \alpha, \beta) \leqslant \max_{\alpha, \beta: \alpha_i \geqslant 0} L(x, \alpha, \beta) = \Theta_P(x)</script><p>所以有</p>
<script type="math/tex; mode=display">
\max_{\alpha, \beta: \alpha_i \geqslant 0} \Theta_D(x) \leqslant \min_x \Theta_P(x)</script><p>则</p>
<script type="math/tex; mode=display">
d^* =  \max_{\alpha, \beta: \alpha_i \geqslant 0} \min_{x}   L(x, \alpha, \beta) \leqslant \min_{x}  \max_{\alpha, \beta: \alpha_i \geqslant 0} L(x, \alpha, \beta) = p^*</script><p>$d^<em> \leqslant p^</em>$ 被称为弱对偶性(weak duality)，当 $d^<em> = p^</em>$ 时被称为强对偶性(strong duality)。那么什么时候强对偶性成立呢，这就要说到<strong>Slater</strong>条件</p>
<ul>
<li>主问题为凸优化问题，$f(x)$ 是凸函数，$g_i(x)$ 是<a href="https://zh.wikipedia.org/wiki/%E5%87%B8%E5%87%BD%E6%95%B0" target="_blank" rel="external">凸函数</a>，$h_j(x)$ 是<a href="https://baike.baidu.com/item/%E4%BB%BF%E5%B0%84%E5%87%BD%E6%95%B0/9276178?fr=aladdin" target="_blank" rel="external">仿射函数</a>，且其可行域中至少有一点使不等式约束严格成立。</li>
</ul>
<p>在满足Slater条件下，强对偶性成立，通过求解对偶问题，主问题也可以解决了。</p>
<h5 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h5><p><strong>KKT</strong> (Karush-Kuhn-Tucker) 条件是判断最优解 $x^*$ 是否为最优解的必要条件。</p>
<script type="math/tex; mode=display">
\begin{cases}
\bigtriangledown f(x)+ \sum_{i=1}^k \alpha_i \bigtriangledown g_i(x) + \sum_{j=1}^l \beta_j \bigtriangledown h_j(x) = 0\\
\\
\alpha_ig_i(x)=0\\
\\
\alpha_i \geqslant 0\\
\\
h_j(x) = 0
\end{cases}</script><h6 id="等式约束问题"><a href="#等式约束问题" class="headerlink" title="等式约束问题"></a>等式约束问题</h6><p>为了便于理解我尽量使用上述提到的符号，在讨论KKT条件前我们先讨论等式约束问题：</p>
<script type="math/tex; mode=display">
\begin{align*}

&\min_{x} f(x) \\
\\
&s.t.\ 
h_j(x) = 0，& j=1,2,\cdots,l\\

\end{align*}</script><p>对于上述问题我们可以引入拉格朗日乘子 $\beta$ 求解</p>
<script type="math/tex; mode=display">
L(x, \beta) = f(x) + \sum_{j=1}^l \beta_j h_j(x)</script><p>然后通过 $L(x, \beta)$ 分别对 $x$ 和 $\beta$ 求导，令其为 0 可得到可能极值点，具体是否为极值点需要根据实际情况验证。</p>
<h6 id="不等式约束问题"><a href="#不等式约束问题" class="headerlink" title="不等式约束问题"></a>不等式约束问题</h6><script type="math/tex; mode=display">
\begin{align*}
&\min_{x} f(x) \\
\\
&s.t.\ 
g_i(x) \leqslant 0，& i=1,2,\cdots,k\\

\end{align*}</script><p>对于上述不等式约束问题我们可以通过引入松弛变量 $ c_i^2$ 将其转化为等式约束问题。</p>
<script type="math/tex; mode=display">
\begin{align*}
&h_i(x, c_i) = g_i(x) + c_i^2 = 0\\
\end{align*}</script><p>同样引入拉格朗日乘子 $\alpha$，构建拉格朗日函数</p>
<script type="math/tex; mode=display">
L(x, \alpha, c) = f(x) + \sum_{i=1}^k \alpha_i (g_i(x) + c_i^2)</script><p>同样对其求导可得</p>
<script type="math/tex; mode=display">
\begin{cases}
\frac{\partial L}{\partial x} = \bigtriangledown f(x)+ \sum_{i=1}^k \alpha_i \bigtriangledown g_i(x) = 0\\
\\
\frac{\partial L}{\partial \alpha_i} = g_i(x) + c_i^2=0\\
\\
\frac{\partial L}{\partial c_i} = 2 \alpha_i c_i = 0\\
\\
\alpha_i \geqslant 0
\end{cases} \tag{}</script><p>观察上式第三个等式，可分为两种情况：</p>
<ul>
<li>$\alpha_i = 0$，$c_i \neq 0$，即乘子为 0，约束 $g_i(x)$ 不起作用，且根据第二个式子 $g_i(x) &lt; 0$</li>
<li>$\alpha_i \geqslant 0$，$c_i = 0$，即松弛变量为 0，约束 $g_i(x)$ 起作用，且根据第二个式子$g_i(x) = 0$ </li>
</ul>
<p>所以第三个等式和第二个等式可以合并成一个等式，合并后的式子便成为不等式约束优化问题的KKT条件</p>
<script type="math/tex; mode=display">
\begin{cases}
\bigtriangledown f(x)+ \sum_{i=1}^k \alpha_i \bigtriangledown g_i(x) = 0\\
\\
\alpha_ig_i(x)=0\\
\\
\alpha_i \geqslant 0
\end{cases} \tag{}</script><p><strong>综上所述，当既有等式约束又有不等式约束时就有了我们之前所说的KTT条件</strong> </p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ML/" rel="tag"># ML</a>
          
            <a href="/tags/SVM/" rel="tag"># SVM</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/12/24/Git笔记/" rel="prev" title="Git笔记">
                Git笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="ScNico" />
          <p class="site-author-name" itemprop="name">ScNico</p>
           
              <p class="site-description motion-element" itemprop="description">Talk is cheap</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#简介"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性可分"><span class="nav-number">2.</span> <span class="nav-text">线性可分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#最大间隔"><span class="nav-number">2.1.</span> <span class="nav-text">最大间隔</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#求解对偶问题"><span class="nav-number">2.2.</span> <span class="nav-text">求解对偶问题</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#求解极小问题"><span class="nav-number">2.2.1.</span> <span class="nav-text">求解极小问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#求解极大问题"><span class="nav-number">2.2.2.</span> <span class="nav-text">求解极大问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SMO"><span class="nav-number">2.2.3.</span> <span class="nav-text">SMO</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#选择变量"><span class="nav-number">2.2.3.1.</span> <span class="nav-text">选择变量</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#二次规划求解"><span class="nav-number">2.2.3.2.</span> <span class="nav-text">二次规划求解</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性不可分"><span class="nav-number">3.</span> <span class="nav-text">线性不可分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#核函数"><span class="nav-number">3.1.</span> <span class="nav-text">核函数</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#多项式核"><span class="nav-number">3.1.1.</span> <span class="nav-text">多项式核</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#高斯核"><span class="nav-number">3.1.2.</span> <span class="nav-text">高斯核</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#其他核函数"><span class="nav-number">3.1.3.</span> <span class="nav-text">其他核函数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#软间隔"><span class="nav-number">3.2.</span> <span class="nav-text">软间隔</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化"><span class="nav-number">4.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#支持向量机回归"><span class="nav-number">5.</span> <span class="nav-text">支持向量机回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拉格朗日对偶性"><span class="nav-number">6.</span> <span class="nav-text">拉格朗日对偶性</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#原始问题"><span class="nav-number">6.0.1.</span> <span class="nav-text">原始问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#对偶问题"><span class="nav-number">6.0.2.</span> <span class="nav-text">对偶问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#原始问题与对偶问题"><span class="nav-number">6.0.3.</span> <span class="nav-text">原始问题与对偶问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#KKT条件"><span class="nav-number">6.0.4.</span> <span class="nav-text">KKT条件</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#等式约束问题"><span class="nav-number">6.0.4.1.</span> <span class="nav-text">等式约束问题</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#不等式约束问题"><span class="nav-number">6.0.4.2.</span> <span class="nav-text">不等式约束问题</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ScNico</span>
  
</div>

<div>
<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次 | 
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>
</div>

        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

</body>
</html>
